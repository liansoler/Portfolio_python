{"cells":[{"cell_type":"markdown","metadata":{"id":"G0LOaPyAgCU8"},"source":["#  RDDs"]},{"cell_type":"markdown","metadata":{"id":"yxqIrsY-gCVB"},"source":["# Creamos un contexto para crear RDDs"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"T3SkkrkIgCVD","executionInfo":{"status":"ok","timestamp":1697623019369,"user_tz":-120,"elapsed":5233,"user":{"displayName":"Larena Mur","userId":"01315359305101069002"}}},"outputs":[],"source":["!pip install pyspark --quiet\n","from pyspark import SparkContext"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"_X-TkHs-gCVE","colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"status":"error","timestamp":1697623024064,"user_tz":-120,"elapsed":247,"user":{"displayName":"Larena Mur","userId":"01315359305101069002"}},"outputId":"b485a451-178b-4c4d-a002-27469eda4943"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-94af41a8f64a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"local\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"TransformacionesyAcciones\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             self._do_init(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Raise error if there is already a running Spark context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    450\u001b[0m                         \u001b[0;34m\"Cannot run multiple SparkContexts at once; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                         \u001b[0;34m\"existing SparkContext(app=%s, master=%s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=TransformacionesyAcciones, master=local) created by __init__ at <ipython-input-2-94af41a8f64a>:1 "]}],"source":["sc = SparkContext(master = \"local\", appName=\"TransformacionesyAcciones\")"]},{"cell_type":"markdown","metadata":{"id":"oYNeSv5EgCVF"},"source":["# Un RDD es una colección inmutable y distribuida de elementos\n","\n","### Spark automaticamente distribuye los datos y paraleliza las operaciones\n","\n","### Los RDD realmente cargan colecciones de datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-yfNRIqPgCVF","executionInfo":{"status":"aborted","timestamp":1697623019369,"user_tz":-120,"elapsed":14,"user":{"displayName":"Larena Mur","userId":"01315359305101069002"}}},"outputs":[],"source":["rdd1 = sc.parallelize([1,2,3])"]},{"cell_type":"markdown","metadata":{"id":"7daw3WsugCVF"},"source":["### Debido a la propiedad de distribución que tienen los RDD, en su creación, podemos particionar los datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gV_9CtH-gCVG","executionInfo":{"status":"aborted","timestamp":1697623019370,"user_tz":-120,"elapsed":15,"user":{"displayName":"Larena Mur","userId":"01315359305101069002"}}},"outputs":[],"source":["import numpy as np\n","rdd2 = sc.parallelize(np.array(range(100)),2)"]},{"cell_type":"markdown","metadata":{"id":"OXf9xyz4gCVG"},"source":["### Verificamos el tipo de dato"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-6IXNzw2gCVG","executionInfo":{"status":"aborted","timestamp":1697623019370,"user_tz":-120,"elapsed":14,"user":{"displayName":"Larena Mur","userId":"01315359305101069002"}}},"outputs":[],"source":["type(rdd1)"]},{"cell_type":"markdown","metadata":{"id":"M9fdoJ87gCVG"},"source":["### Vemos el contenido\n","\n","Veremos distintas tecnicas apropiadas para ver el contenido de los RDDs y Dataframes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QzqUUjhCgCVH","executionInfo":{"status":"aborted","timestamp":1697623019370,"user_tz":-120,"elapsed":14,"user":{"displayName":"Larena Mur","userId":"01315359305101069002"}}},"outputs":[],"source":["rdd1.collect()"]},{"cell_type":"markdown","metadata":{"id":"cvXwqRwdgCVH"},"source":["# Carga de un arhivo CSV"]},{"cell_type":"markdown","metadata":{"id":"OfQ67xw1gCVI"},"source":["### Cargamos un RDDs\n","\n","El método textFile busca el archivo en la ruta indicada\n","\n","Cambia el valor de la ruta para que apunte a la ruta donde tienes los datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9AG-1zOcgCVI","executionInfo":{"status":"aborted","timestamp":1697623019371,"user_tz":-120,"elapsed":15,"user":{"displayName":"Larena Mur","userId":"01315359305101069002"}}},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","equiposOlimpicosRDD = sc.textFile(\"/content/drive/MyDrive/Colab Notebooks/RED.ES/Datos Ejercicios/M6/paises.csv\",2).map(lambda line : line.split(\",\"))"]},{"cell_type":"markdown","metadata":{"id":"FGKXqN4sgCVI"},"source":["### Vemos el contenido\n","\n","El método take es otro método existnte para poder visualizar el contenido de los RDDs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HA3o7cq1gCVI","executionInfo":{"status":"aborted","timestamp":1697623019371,"user_tz":-120,"elapsed":15,"user":{"displayName":"Larena Mur","userId":"01315359305101069002"}}},"outputs":[],"source":["equiposOlimpicosRDD.take(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LfOUKBkvgCVJ","executionInfo":{"status":"aborted","timestamp":1697623019372,"user_tz":-120,"elapsed":16,"user":{"displayName":"Larena Mur","userId":"01315359305101069002"}}},"outputs":[],"source":["sc.stop()"]},{"cell_type":"markdown","source":["## Ejercicio:\n","\n","Intenta leer un archivo csv o de texto y hacer alguna transformación.\n","\n","* Busca el archivo del quijote.txt por internet.\n","* Subelo a Google COlab e importalo con pyspark.\n","* Cuenta los caracteres del fichero."],"metadata":{"id":"a0DSWeq2xcEH"}},{"cell_type":"code","source":["#Inserta aquí tú código\n"],"metadata":{"id":"vSx9LCyjxo9f","executionInfo":{"status":"aborted","timestamp":1697623019374,"user_tz":-120,"elapsed":18,"user":{"displayName":"Larena Mur","userId":"01315359305101069002"}}},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[{"file_id":"1bB5s6wfR7BmWZitfFkhiFLH0YhleTOsP","timestamp":1697622770897},{"file_id":"https://github.com/terranigmark/curso-apache-spark-platzi/blob/master/2.%20Primer%20RDD.ipynb","timestamp":1672143190353}]}},"nbformat":4,"nbformat_minor":0}